{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Name  ID Salary  Role\n",
      "0  Pankaj   1    100   CEO\n",
      "1  Meghna   2    200  None\n",
      "2   David   3    NaN   NaT\n",
      "3    Lisa   4    NaT   NaT\n",
      "     Name  ID Salary Role\n",
      "0  Pankaj   1    100  CEO\n"
     ]
    }
   ],
   "source": [
    "# Removing NA values\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "d1 = {'Name': ['Pankaj', 'Meghna', 'David', 'Lisa'], 'ID': [1, 2, 3, 4], 'Salary': [100, 200, np.nan, pd.NaT],\n",
    "      'Role': ['CEO', None, pd.NaT, pd.NaT]}\n",
    "\n",
    "df = pd.DataFrame(d1)\n",
    "\n",
    "print(df)\n",
    "\n",
    "# drop all rows with any NaN and NaT values\n",
    "df1 = df.dropna()\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Name  ID Salary\n",
      "0  Pankaj   1    100\n",
      "1  Meghna   2    NaT\n",
      "     Name  ID Salary\n",
      "0  Pankaj   1    100\n"
     ]
    }
   ],
   "source": [
    "# Dropping rows with NA values\n",
    "import pandas as pd\n",
    "\n",
    "d1 = {'Name': ['Pankaj', 'Meghna'], 'ID': [1, 2], 'Salary': [100, pd.NaT]}\n",
    "\n",
    "df = pd.DataFrame(d1)\n",
    "\n",
    "print(df)\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Name   ID Salary Role\n",
      "0  Pankaj    1    100  NaT\n",
      "1  Meghna    2    200  NaT\n",
      "2   David    3    NaN  NaT\n",
      "3     NaT  NaT    NaT  NaT\n",
      "     Name ID Salary Role\n",
      "0  Pankaj  1    100  NaT\n",
      "1  Meghna  2    200  NaT\n",
      "2   David  3    NaN  NaT\n",
      "     Name   ID Salary\n",
      "0  Pankaj    1    100\n",
      "1  Meghna    2    200\n",
      "2   David    3    NaN\n",
      "3     NaT  NaT    NaT\n"
     ]
    }
   ],
   "source": [
    "# Drop Row/Column Only if All the Values are Null\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "d1 = {'Name': ['Pankaj', 'Meghna', 'David', pd.NaT], 'ID': [1, 2, 3, pd.NaT], 'Salary': [100, 200, np.nan, pd.NaT],\n",
    "      'Role': [np.nan, np.nan, pd.NaT, pd.NaT]}\n",
    "\n",
    "df = pd.DataFrame(d1)\n",
    "\n",
    "print(df)\n",
    "\n",
    "df1 = df.dropna(how='all')\n",
    "print(df1)\n",
    "\n",
    "df1 = df.dropna(how='all', axis=1)\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputing example\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_boston\n",
    " \n",
    "boston_bunch = load_boston()\n",
    "dfx = pd.DataFrame(boston_bunch.data, columns = boston_bunch.feature_names) #independent variables\n",
    "dfy = pd.DataFrame(boston_bunch.target, columns = ['target']) #dependent variables\n",
    "boston = dfx.join(dfy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIM       0\n",
       "ZN         0\n",
       "INDUS      0\n",
       "CHAS       0\n",
       "NOX        0\n",
       "RM         0\n",
       "AGE        0\n",
       "DIS        0\n",
       "RAD        0\n",
       "TAX        0\n",
       "PTRATIO    0\n",
       "B          0\n",
       "LSTAT      0\n",
       "target     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding the sum of null values\n",
    "boston.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing 20% values to NaN\n",
    "import collections\n",
    "import random\n",
    "df = boston\n",
    "replaced = collections.defaultdict(set)\n",
    "ix = [(row, col) for row in range(df.shape[0]) for col in range(df.shape[1])]\n",
    "random.shuffle(ix)\n",
    "to_replace = int(round(.2*len(ix)))\n",
    "for row, col in ix:\n",
    "    if len(replaced[row]) < df.shape[1] - 1:\n",
    "        df.iloc[row, col] = np.nan\n",
    "        to_replace -= 1\n",
    "        replaced[row].add(col)\n",
    "        if to_replace == 0:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIM        92\n",
       "ZN         102\n",
       "INDUS      105\n",
       "CHAS       112\n",
       "NOX        104\n",
       "RM         106\n",
       "AGE         92\n",
       "DIS         91\n",
       "RAD         99\n",
       "TAX        105\n",
       "PTRATIO    108\n",
       "B          114\n",
       "LSTAT      106\n",
       "target      81\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding the sum of null values\n",
    "boston.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NA with mean() of each column in boston dataset\n",
    "df = df.apply(lambda x: x.fillna(x.mean()),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "arr1 :  [[20, 2, 7, 1, 34], [50, 12, 12, 34, 4]]\n",
      "\n",
      "arr2 :  [[50, 12, 12, 34, 4], [12, 11, 10, 34, 21]]\n",
      "\n",
      "Z-score for arr1 : \n",
      " [[-1. -1. -1. -1.  1.]\n",
      " [ 1.  1.  1.  1. -1.]]\n",
      "\n",
      "Z-score for arr1 : \n",
      " [[ 0.57251144 -0.85876716 -0.46118977 -0.93828264  1.68572813]\n",
      " [ 1.62005758 -0.61045648 -0.61045648  0.68089376 -1.08003838]]\n"
     ]
    }
   ],
   "source": [
    "# Z-Score\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "    \n",
    "arr1 = [[20, 2, 7, 1, 34],\n",
    "        [50, 12, 12, 34, 4]]\n",
    "  \n",
    "arr2 = [[50, 12, 12, 34, 4], \n",
    "        [12, 11, 10, 34, 21]]\n",
    "  \n",
    "print (\"\\narr1 : \", arr1)\n",
    "print (\"\\narr2 : \", arr2)\n",
    "  \n",
    "print (\"\\nZ-score for arr1 : \\n\", stats.zscore(arr1))\n",
    "print (\"\\nZ-score for arr1 : \\n\", stats.zscore(arr1, axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0e+02 1.0e-03]\n",
      " [8.0e+00 5.0e-02]\n",
      " [5.0e+01 5.0e-03]\n",
      " [8.8e+01 7.0e-02]\n",
      " [4.0e+00 1.0e-01]]\n",
      "[[1.         0.        ]\n",
      " [0.04166667 0.49494949]\n",
      " [0.47916667 0.04040404]\n",
      " [0.875      0.6969697 ]\n",
      " [0.         1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Min-Max Scalar\n",
    "from numpy import asarray\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# define data\n",
    "data = asarray([[100, 0.001],\n",
    "                [8, 0.05],\n",
    "                [50, 0.005],\n",
    "                [88, 0.07],\n",
    "                [4, 0.1]])\n",
    "print(data)\n",
    "# define min max scaler\n",
    "scaler = MinMaxScaler()\n",
    "# transform data\n",
    "scaled = scaler.fit_transform(data)\n",
    "print(scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0e+02 1.0e-03]\n",
      " [8.0e+00 5.0e-02]\n",
      " [5.0e+01 5.0e-03]\n",
      " [8.8e+01 7.0e-02]\n",
      " [4.0e+00 1.0e-01]]\n",
      "[[ 1.26398112 -1.16389967]\n",
      " [-1.06174414  0.12639634]\n",
      " [ 0.         -1.05856939]\n",
      " [ 0.96062565  0.65304778]\n",
      " [-1.16286263  1.44302493]]\n"
     ]
    }
   ],
   "source": [
    "# Standardization\n",
    "from numpy import asarray\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# define data\n",
    "data = asarray([[100, 0.001],\n",
    "                [8, 0.05],\n",
    "                [50, 0.005],\n",
    "                [88, 0.07],\n",
    "                [4, 0.1]])\n",
    "print(data)\n",
    "# define standard scaler\n",
    "scaler = StandardScaler()\n",
    "# transform data\n",
    "scaled = scaler.fit_transform(data)\n",
    "print(scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bridge_Types</th>\n",
       "      <th>Bridge_Types_Cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arch</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beam</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Truss</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cantilever</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tied Arch</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Suspension</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Cable</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Bridge_Types  Bridge_Types_Cat\n",
       "0         Arch                 0\n",
       "1         Beam                 1\n",
       "2        Truss                 6\n",
       "3   Cantilever                 3\n",
       "4    Tied Arch                 5\n",
       "5   Suspension                 4\n",
       "6        Cable                 2"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Label Encoding\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# creating initial dataframe\n",
    "bridge_types = ('Arch','Beam','Truss','Cantilever','Tied Arch','Suspension','Cable')\n",
    "bridge_df = pd.DataFrame(bridge_types, columns=['Bridge_Types'])\n",
    "# creating instance of labelencoder\n",
    "labelencoder = LabelEncoder()\n",
    "# Assigning numerical values and storing in another column\n",
    "bridge_df['Bridge_Types_Cat'] = labelencoder.fit_transform(bridge_df['Bridge_Types'])\n",
    "bridge_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
